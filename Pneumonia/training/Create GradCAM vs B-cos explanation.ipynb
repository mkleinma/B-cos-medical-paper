{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Admin/.cache\\torch\\hub\\B-cos_B-cos-v2_main\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\bcos\\common.py:152: UserWarning: Input tensor did not require grad! Has been set automatically to True!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.transforms import functional as TF\n",
    "from PIL import Image\n",
    "from libraries.bcosconv2d import NormedConv2d\n",
    "import pydicom \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from libraries.bcosconv2d import NormedConv2d\n",
    "from libraries.bcoslinear import BcosLinear\n",
    "from pooling.flc_bcosconv2d import ModifiedFLCBcosConv2d\n",
    "\n",
    "from pytorch_grad_cam import GradCAM  \n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Paths\n",
    "csv_path = r\"G:\\Meine Ablage\\Universität\\Master Thesis\\Pneumonia\\training\\grouped_data.csv\"\n",
    "image_folder = r\"C:\\Users\\Admin\\Documents\\rsna-pneumonia-detection-challenge\\stage_2_train_images\"\n",
    "splits_path = r\"G:\\Meine Ablage\\Universität\\Master Thesis\\Pneumonia\\training\\splits\\splits_balanced_fix.pkl\"\n",
    "model_path = r\"C:\\Users\\Admin\\Documents\\MasterThesis\\results\\ResNet50_BCos\\light_oversamp_nonorm\\seed_0\\pneumonia_detection_model_resnet_bcos_bestf1_1.pth\"\n",
    "\n",
    "# Load splits\n",
    "with open(splits_path, 'rb') as f:\n",
    "    splits = pickle.load(f)\n",
    "\n",
    "# Dataset class\n",
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_folder, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_path = os.path.join(self.image_folder, f\"{row['patientId']}.dcm\")\n",
    "        label = row['Target']\n",
    "        patient_id = row['patientId']\n",
    "\n",
    "        dicom = pydicom.dcmread(image_path)\n",
    "        image = dicom.pixel_array\n",
    "        image = Image.fromarray(image).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long), patient_id\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = torch.hub.load('B-cos/B-cos-v2', 'resnet50', pretrained=True)\n",
    "model.fc.linear = NormedConv2d(2048, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "\n",
    "# Transformations and data loader setup\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "data = pd.read_csv(csv_path)\n",
    "first_split = splits[0]\n",
    "val_idx = first_split[1]\n",
    "val_data = data.iloc[val_idx]\n",
    "val_dataset = PneumoniaDataset(val_data, image_folder, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Output directory setup\n",
    "directory = r\"C:\\Users\\Admin\\Documents\\MasterThesis\\comparison_images\\ResNet50_BCos_GradCAM\"\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for images, labels, patient_ids in val_loader:\n",
    "        if i > 100:\n",
    "            break\n",
    "        images = images.to(device)\n",
    "        six_channel_images = []\n",
    "        \n",
    "        for img_tensor in images:\n",
    "            numpy_image = (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "            pil_image = Image.fromarray(numpy_image)\n",
    "            transformed_image = model.transform(pil_image)\n",
    "            six_channel_images.append(transformed_image)\n",
    "        six_channel_images = torch.stack(six_channel_images).to(device)\n",
    "\n",
    "        for image, patient_id in zip(six_channel_images, patient_ids):\n",
    "            if i > 100:\n",
    "                break\n",
    "            image = image[None]\n",
    "            expl = model.explain(image)\n",
    "            filename = f\"{patient_id}_bcos_explanation.png\"\n",
    "            image_path_worse = os.path.join(directory, filename)\n",
    "            plt.figure()\n",
    "            plt.imshow(expl[\"explanation\"])\n",
    "            plt.axis('off')\n",
    "            plt.savefig(image_path_worse, bbox_inches=\"tight\", pad_inches=0)\n",
    "            plt.close()\n",
    "            i += 1            \n",
    "            \n",
    "            \n",
    "model.train()\n",
    "target_layer = model.layer4[-1]\n",
    "gradcam = GradCAM(model=model, target_layers=[target_layer])\n",
    "\n",
    "i = 0\n",
    "for images, labels, patient_ids in val_loader:\n",
    "    if i > 100:\n",
    "        break\n",
    "    \n",
    "    original_images = [(img.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
    "    images = images.to(device)\n",
    "    \n",
    "    six_channel_images = []\n",
    "    for img_tensor in images:\n",
    "        numpy_image = (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "        pil_image = Image.fromarray(numpy_image)\n",
    "        transformed_image = model.transform(pil_image)\n",
    "        six_channel_images.append(transformed_image)\n",
    "    six_channel_images = torch.stack(six_channel_images).to(device)\n",
    "\n",
    "    \n",
    "    for idx, (image, patient_id) in enumerate(zip(six_channel_images, patient_ids)):\n",
    "        if i > 100:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        image.requires_grad_(True)  # Enable gradients for Grad-CAM processing\n",
    "        \n",
    "        grayscale_cam = gradcam(input_tensor=image.unsqueeze(0))[0]\n",
    "        \n",
    "        rgb_img = original_images[idx] / 255.0\n",
    "        heatmap_resized = cv2.resize(grayscale_cam,\n",
    "                                     (rgb_img.shape[1], rgb_img.shape[0]))\n",
    "        \n",
    "        cam_image = show_cam_on_image(rgb_img, heatmap_resized)\n",
    "\n",
    "        # Save Grad-CAM visualization\n",
    "        filename_gradcam = f\"{patient_id}_gradcam.png\"\n",
    "        path_gradcam = os.path.join(directory, filename_gradcam)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(cam_image)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(path_gradcam, bbox_inches=\"tight\", pad_inches=0)\n",
    "        plt.close()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
