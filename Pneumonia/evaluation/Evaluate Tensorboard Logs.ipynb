{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Logs\n",
    "Tensorboard logs play a huge role in evaluating our model performance\n",
    "This script focuses on getting the necessary information from a log directory to have educated information on the model performance.\n",
    "\n",
    "The first cell (directly below) focuses on deriving the best F1-Score and Recall model\n",
    "The second cell focuses on deriving from a directory of several folds (considering this project uses five-fold cross validation) the average across all folds of the necessary metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "DirectoryDeletedError",
     "evalue": "Directory C:\\Users\\Admin\\Documents\\MasterThesis\\results\\Pneumonia\\Resnet_FLC\\no_nosamp\\seed_0\\tensorboard_logs_fold_3 has been permanently deleted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:88\u001b[0m, in \u001b[0;36mDirectoryWatcher.Load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_LoadInternal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:110\u001b[0m, in \u001b[0;36mDirectoryWatcher._LoadInternal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loader:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_InitializeLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# If it still doesn't exist, there is no data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:173\u001b[0m, in \u001b[0;36mDirectoryWatcher._InitializeLoader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_InitializeLoader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GetNextPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:210\u001b[0m, in \u001b[0;36mDirectoryWatcher._GetNextPath\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the next path to load from.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03mThis function also does the checking for out-of-order writes as it iterates\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m  The next path to load events from, or None if there are no more paths.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    208\u001b[0m paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    209\u001b[0m     path\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mio_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mListDirectoryAbsolute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_filter(path)\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\io_wrapper.py:78\u001b[0m, in \u001b[0;36mListDirectoryAbsolute\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields all files in the given directory.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mThe paths are absolute.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m---> 78\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:896\u001b[0m, in \u001b[0;36mlistdir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 896\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_filesystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:200\u001b[0m, in \u001b[0;36mLocalFileSystem.listdir\u001b[1;34m(self, dirname)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misdir(dirname):\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    202\u001b[0m entries \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(compat\u001b[38;5;241m.\u001b[39mas_str_any(dirname))\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDirectoryDeletedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#log_dir = r\"C:\\Users\\Admin\\Documents\\MasterThesis\\results\\Pneumonia\\ResNet50_BCos\\light_oversamp\\seed_0\\tensorboard_logs_fold_1\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m event_acc \u001b[38;5;241m=\u001b[39m EventAccumulator(log_dir)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mevent_acc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# List all available scalars\u001b[39;00m\n\u001b[0;32m     11\u001b[0m available_tags \u001b[38;5;241m=\u001b[39m event_acc\u001b[38;5;241m.\u001b[39mTags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscalars\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\event_accumulator.py:343\u001b[0m, in \u001b[0;36mEventAccumulator.Reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads all events added since the last call to `Reload`.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03mIf `Reload` was never called, loads all events in the file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m  The `EventAccumulator`.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator_mutex:\n\u001b[1;32m--> 343\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ProcessEvent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:92\u001b[0m, in \u001b[0;36mDirectoryWatcher.Load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directory):\n\u001b[1;32m---> 92\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DirectoryDeletedError(\n\u001b[0;32m     93\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m has been permanently deleted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directory\n\u001b[0;32m     95\u001b[0m         )\n",
      "\u001b[1;31mDirectoryDeletedError\u001b[0m: Directory C:\\Users\\Admin\\Documents\\MasterThesis\\results\\Pneumonia\\Resnet_FLC\\no_nosamp\\seed_0\\tensorboard_logs_fold_3 has been permanently deleted"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "log_dir = r\"C:\\Users\\Admin\\Documents\\MasterThesis\\results\\Pneumonia\\Resnet_FLC\\no_nosamp\\seed_0\\tensorboard_logs_fold_3\"\n",
    "#log_dir = r\"C:\\Users\\Admin\\Documents\\MasterThesis\\results\\Pneumonia\\ResNet50_BCos\\light_oversamp\\seed_0\\tensorboard_logs_fold_1\"\n",
    "\n",
    "event_acc = EventAccumulator(log_dir)\n",
    "event_acc.Reload()\n",
    "\n",
    "# List all available scalars\n",
    "available_tags = event_acc.Tags()[\"scalars\"]\n",
    "print(\"Available scalars:\", available_tags)\n",
    "\n",
    "# Extract scalar values per epoch\n",
    "precision_values = event_acc.Scalars(\"Metrics/Precision\")\n",
    "accuracy_values = event_acc.Scalars(\"Accuracy/Validation\")\n",
    "f1_values = event_acc.Scalars(\"Metrics/F1\")\n",
    "recall_values = event_acc.Scalars(\"Metrics/Recall\")\n",
    "auc_values = event_acc.Scalars(\"Metrics/AUC\")\n",
    "\n",
    "\n",
    "# Get epoch-wise values\n",
    "epochs = [x.step for x in precision_values]\n",
    "accuracy_scores = [x.value for x in accuracy_values]\n",
    "f1_scores = [x.value for x in f1_values]\n",
    "precision_scores = [x.value for x in precision_values]  # Convert to list\n",
    "recall_scores = [x.value for x in recall_values]  # Convert to list\n",
    "\n",
    "# Compute mean, min, max precision\n",
    "mean_precision = np.mean(precision_scores)\n",
    "minimum_precision = np.min(precision_scores)\n",
    "maximum_precision = np.max(precision_scores)\n",
    "\n",
    "print(f\"Mean Average Precision (mAP): {mean_precision}\")\n",
    "print(f\"Min Precision: {minimum_precision}\")\n",
    "print(f\"Max Precision: {maximum_precision}\")\n",
    "\n",
    "print()\n",
    "\n",
    "mean_recall = np.mean(recall_scores)\n",
    "minimum_recall = np.min(recall_scores)\n",
    "maximum_recall = np.max(recall_scores)\n",
    "\n",
    "print(f\"Mean Average Recall (mAR): {mean_recall}\")\n",
    "print(f\"Min Recall: {minimum_recall}\")\n",
    "print(f\"Max Recall: {maximum_recall}\")\n",
    "\n",
    "\n",
    "# Compute mean, min, max accuracy\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "minimum_accuracy = np.min(accuracy_scores)\n",
    "maximum_accuracy = np.max(accuracy_scores)\n",
    "\n",
    "print()\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Min Accuracy: {minimum_accuracy}\")\n",
    "print(f\"Max Accuracy: {maximum_accuracy}\")\n",
    "\n",
    "\n",
    "best_accuracy_idx = np.argmax(accuracy_scores)\n",
    "best_acc_epoch = epochs[best_accuracy_idx]\n",
    "best_acc_f1 = f1_scores[best_accuracy_idx]\n",
    "best_acc_precision = precision_values[best_accuracy_idx].value\n",
    "best_acc_recall = recall_values[best_accuracy_idx].value  \n",
    "best_acc_accuracy = accuracy_values[best_accuracy_idx].value\n",
    "best_acc_auc = auc_values[best_accuracy_idx].value\n",
    "\n",
    "print()\n",
    "print(f\"Corresponding Accuracy: {best_acc_accuracy} at Epoch {best_accuracy_idx}\")\n",
    "print(f\"Corresponding Precision: {best_acc_precision}\")\n",
    "print(f\"Highest Recall: {best_acc_recall}\")\n",
    "print(f\"Corresponding F1 Score: {best_acc_f1}\")\n",
    "print(f\"Corresponding AUC: {best_acc_auc}\")\n",
    "print()\n",
    "\n",
    "# Find best epoch based on highest F1 score\n",
    "best_f1_idx = np.argmax(f1_scores)\n",
    "best_f1_epoch = epochs[best_f1_idx]\n",
    "best_f1 = f1_scores[best_f1_idx]\n",
    "best_f1_precision = precision_values[best_f1_idx].value\n",
    "best_f1_recall = recall_values[best_f1_idx].value  \n",
    "best_f1_accuracy = accuracy_values[best_f1_idx].value\n",
    "best_f1_auc = auc_values[best_f1_idx].value\n",
    "\n",
    "\n",
    "best_f1_precision = round(best_f1_precision, 4)\n",
    "best_f1_recall = round(best_f1_recall, 4)\n",
    "best_f1_accuracy = round(best_f1_accuracy, 4)\n",
    "best_f1_auc = round(best_f1_auc, 4)\n",
    "best_f1_f1 = round(best_f1, 4)\n",
    "\n",
    "print()\n",
    "print(f\"Corresponding Accuracy: {best_f1_accuracy}\")\n",
    "print(f\"Corresponding Precision: {best_f1_precision}\")\n",
    "print(f\"Corresponding Recall: {best_f1_recall}\")\n",
    "print(f\"Highest F1 Score: {best_f1_f1} at Epoch {best_f1_epoch}\")\n",
    "print(f\"Corresponding AUC: {best_f1_auc}\")\n",
    "\n",
    "best_recall_idx = np.argmax(recall_scores)\n",
    "best_recall_epoch = epochs[best_recall_idx]\n",
    "best_recall_f1 = f1_scores[best_recall_idx]\n",
    "best_recall_precision = precision_values[best_recall_idx].value\n",
    "best_recall_recall = recall_values[best_recall_idx].value  \n",
    "best_recall_accuracy = accuracy_values[best_recall_idx].value\n",
    "best_recall_auc = auc_values[best_recall_idx].value\n",
    "\n",
    "\n",
    "best_recall_precision = round(best_recall_precision, 4)\n",
    "best_recall_recall = round(best_recall_recall, 4)\n",
    "best_recall_accuracy = round(best_recall_accuracy, 4)\n",
    "best_recall_auc = round(best_recall_auc, 4)\n",
    "best_recall_f1 = round(best_recall_f1, 4)\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(f\"Corresponding Accuracy: {best_recall_accuracy}\")\n",
    "print(f\"Corresponding Precision: {best_recall_precision}\")\n",
    "print(f\"Highest Recall: {best_recall_recall} at Epoch {best_recall_epoch}\")\n",
    "print(f\"Corresponding F1 Score: {best_recall_f1}\")\n",
    "print(f\"Corresponding AUC: {best_recall_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= AVERAGE METRICS OVER ALL FOLDS =======\n",
      "\n",
      "Best F1 Model:\n",
      "Mean Accuracy: 0.8\n",
      "Mean Precision: 0.5403\n",
      "Mean Recall: 0.7528\n",
      "Mean F1 Score: 0.629\n",
      "Mean AUC: 0.8668\n",
      "\n",
      "Best Recall Model:\n",
      "Mean Accuracy: 0.6639\n",
      "Mean Precision: 0.3987\n",
      "Mean Recall: 0.9032\n",
      "Mean F1 Score: 0.5509\n",
      "Mean AUC: 0.8589\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "log_base_dir = r\"C:\\Users\\Admin\\Documents\\MasterThesis\\results\\Pneumonia\\ResNet50_Blur\\light_oversamp\\seed_0\\tensorboard_logs_fold_\"\n",
    "# log_base_dir = r\"C:\\Users\\Admin\\Documents\\MasterThesis\\results\\Pneumonia\\ResNet50_BCos\\light_oversamp\\seed_0\\tensorboard_logs_fold_\"\n",
    "# need to download transformer light no oversamp!!!!!!!! baseline\n",
    "\n",
    "num_folds = 5  # Number of folds\n",
    "\n",
    "# Lists to store best values for each fold\n",
    "best_f1_f1, best_f1_precisions, best_f1_recalls, best_f1_accuracies, best_f1_aucs = [], [], [], [], []\n",
    "best_recall_f1, best_recall_precisions, best_recall_recalls, best_recall_accuracies, best_recall_aucs = [], [], [], [], []\n",
    "\n",
    "for fold in range(1, num_folds + 1):\n",
    "    log_dir = f\"{log_base_dir}{fold}\"\n",
    "    import os\n",
    "    if not os.path.exists(log_dir):\n",
    "        print(f\"CAREFUL {log_dir} does not exist\")\n",
    "        continue\n",
    "    \n",
    "    event_acc = EventAccumulator(log_dir)\n",
    "    event_acc.Reload()\n",
    "    \n",
    "    precision_values = event_acc.Scalars(\"Metrics/Precision\")\n",
    "    accuracy_values = event_acc.Scalars(\"Accuracy/Validation\")\n",
    "    f1_values = event_acc.Scalars(\"Metrics/F1\")\n",
    "    recall_values = event_acc.Scalars(\"Metrics/Recall\")\n",
    "    auc_values = event_acc.Scalars(\"Metrics/AUC\")\n",
    "    \n",
    "    epochs = [x.step for x in precision_values]\n",
    "    accuracy_scores = [x.value for x in accuracy_values]\n",
    "    f1_scores = [x.value for x in f1_values]\n",
    "    precision_scores = [x.value for x in precision_values]\n",
    "    recall_scores = [x.value for x in recall_values]\n",
    "    auc_scores = [x.value for x in auc_values]\n",
    "    \n",
    "    # Best F1 Score Model\n",
    "    best_f1_idx = np.argmax(f1_scores)\n",
    "    best_f1_f1.append(f1_scores[best_f1_idx])\n",
    "    best_f1_precisions.append(precision_scores[best_f1_idx])\n",
    "    best_f1_recalls.append(recall_scores[best_f1_idx])\n",
    "    best_f1_accuracies.append(accuracy_scores[best_f1_idx])\n",
    "    best_f1_aucs.append(auc_scores[best_f1_idx])\n",
    "    \n",
    "    # Best Recall Score Model\n",
    "    best_recall_idx = np.argmax(recall_scores)\n",
    "    best_recall_f1.append(f1_scores[best_recall_idx])\n",
    "    best_recall_precisions.append(precision_scores[best_recall_idx])\n",
    "    best_recall_recalls.append(recall_scores[best_recall_idx])\n",
    "    best_recall_accuracies.append(accuracy_scores[best_recall_idx])\n",
    "    best_recall_aucs.append(auc_scores[best_recall_idx])\n",
    "\n",
    "# Compute mean values across all folds\n",
    "def compute_mean(lst):\n",
    "    return round(np.mean(lst), 4) if lst else None\n",
    "\n",
    "print(\"\\n======= AVERAGE METRICS OVER ALL FOLDS =======\")\n",
    "print(\"\\nBest F1 Model:\")\n",
    "print(f\"Mean Accuracy: {compute_mean(best_f1_accuracies)}\")\n",
    "print(f\"Mean Precision: {compute_mean(best_f1_precisions)}\")\n",
    "print(f\"Mean Recall: {compute_mean(best_f1_recalls)}\")\n",
    "print(f\"Mean F1 Score: {compute_mean(best_f1_f1)}\")\n",
    "print(f\"Mean AUC: {compute_mean(best_f1_aucs)}\")\n",
    "\n",
    "print(\"\\nBest Recall Model:\")\n",
    "print(f\"Mean Accuracy: {compute_mean(best_recall_accuracies)}\")\n",
    "print(f\"Mean Precision: {compute_mean(best_recall_precisions)}\")\n",
    "print(f\"Mean Recall: {compute_mean(best_recall_recalls)}\")\n",
    "print(f\"Mean F1 Score: {compute_mean(best_recall_f1)}\")\n",
    "print(f\"Mean AUC: {compute_mean(best_recall_aucs)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Individual Seed Results ===\n",
      "\n",
      "Seed 0 - Best F1 Networks:\n",
      "Accuracy: 79.9955\n",
      "Precision: 54.0254\n",
      "Recall: 75.2826\n",
      "F1: 62.8994\n",
      "AUC: 86.6768\n",
      "\n",
      "Seed 1 - Best F1 Networks:\n",
      "Accuracy: 81.0262\n",
      "Precision: 56.9002\n",
      "Recall: 71.7720\n",
      "F1: 63.0096\n",
      "AUC: 86.5778\n",
      "\n",
      "=== Final Cross-Seed Statistics ===\n",
      "Accuracy: 80.51% ± 0.52%\n",
      "Precision: 55.46% ± 1.44%\n",
      "Recall: 73.53% ± 1.76%\n",
      "F1 Score: 62.95% ± 0.06%\n",
      "AUC: 86.63% ± 0.05%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "log_base_dir = r\"C:\\Users\\Admin\\Documents\\MasterThesis\\results\\Pneumonia\\ResNet50_Blur\\light_oversamp\"\n",
    "seeds = [0, 1]  # Two seeds to process\n",
    "num_folds = 5\n",
    "\n",
    "def process_seed(seed):\n",
    "    seed_metrics = {\n",
    "        'f1': {'acc': [], 'prec': [], 'rec': [], 'f1': [], 'auc': []},\n",
    "        'recall': {'acc': [], 'prec': [], 'rec': [], 'f1': [], 'auc': []}\n",
    "    }\n",
    "    \n",
    "    for fold in range(1, num_folds + 1):\n",
    "        log_dir = os.path.join(log_base_dir, f\"seed_{seed}\", f\"tensorboard_logs_fold_{fold}\")\n",
    "        if not os.path.exists(log_dir):\n",
    "            print(f\"Missing: {log_dir}\")\n",
    "            continue\n",
    "\n",
    "        event_acc = EventAccumulator(log_dir)\n",
    "        event_acc.Reload()\n",
    "        \n",
    "        # Extract metrics\n",
    "        metrics = {\n",
    "            'acc': [x.value * 100 for x in event_acc.Scalars(\"Accuracy/Validation\")],\n",
    "            'prec': [x.value * 100 for x in event_acc.Scalars(\"Metrics/Precision\")],\n",
    "            'rec': [x.value * 100 for x in event_acc.Scalars(\"Metrics/Recall\")],\n",
    "            'f1': [x.value * 100 for x in event_acc.Scalars(\"Metrics/F1\")],\n",
    "            'auc': [x.value * 100 for x in event_acc.Scalars(\"Metrics/AUC\")]\n",
    "        }\n",
    "\n",
    "        # Best F1 model\n",
    "        best_f1_idx = np.argmax(metrics['f1'])\n",
    "        seed_metrics['f1']['acc'].append(metrics['acc'][best_f1_idx])\n",
    "        seed_metrics['f1']['prec'].append(metrics['prec'][best_f1_idx])\n",
    "        seed_metrics['f1']['rec'].append(metrics['rec'][best_f1_idx])\n",
    "        seed_metrics['f1']['f1'].append(metrics['f1'][best_f1_idx])\n",
    "        seed_metrics['f1']['auc'].append(metrics['auc'][best_f1_idx])\n",
    "\n",
    "        # Best Recall model\n",
    "        best_rec_idx = np.argmax(metrics['rec'])\n",
    "        seed_metrics['recall']['acc'].append(metrics['acc'][best_rec_idx])\n",
    "        seed_metrics['recall']['prec'].append(metrics['prec'][best_rec_idx])\n",
    "        seed_metrics['recall']['rec'].append(metrics['rec'][best_rec_idx])\n",
    "        seed_metrics['recall']['f1'].append(metrics['f1'][best_rec_idx])\n",
    "        seed_metrics['recall']['auc'].append(metrics['auc'][best_rec_idx])\n",
    "    \n",
    "    return seed_metrics\n",
    "\n",
    "def compute_stats(data):\n",
    "    return f\"{np.mean(data):.2f}% ± {np.std(data):.2f}%\"\n",
    "\n",
    "# Process both seeds\n",
    "all_seeds = {seed: process_seed(seed) for seed in seeds}\n",
    "\n",
    "# Aggregate results across seeds for best F1 networks\n",
    "final_metrics = {\n",
    "    'acc': [],\n",
    "    'prec': [],\n",
    "    'rec': [],\n",
    "    'f1': [],\n",
    "    'auc': []\n",
    "}\n",
    "\n",
    "for seed in seeds:\n",
    "    seed_data = all_seeds[seed]['f1']\n",
    "    final_metrics['acc'].append(np.mean(seed_data['acc']))\n",
    "    final_metrics['prec'].append(np.mean(seed_data['prec']))\n",
    "    final_metrics['rec'].append(np.mean(seed_data['rec']))\n",
    "    final_metrics['f1'].append(np.mean(seed_data['f1']))\n",
    "    final_metrics['auc'].append(np.mean(seed_data['auc']))\n",
    "\n",
    "# Print results\n",
    "print(\"=== Individual Seed Results ===\")\n",
    "for seed in seeds:\n",
    "    print(f\"\\nSeed {seed} - Best F1 Networks:\")\n",
    "    print(f\"Accuracy: {np.mean(all_seeds[seed]['f1']['acc']):.4f}\")\n",
    "    print(f\"Precision: {np.mean(all_seeds[seed]['f1']['prec']):.4f}\")\n",
    "    print(f\"Recall: {np.mean(all_seeds[seed]['f1']['rec']):.4f}\") \n",
    "    print(f\"F1: {np.mean(all_seeds[seed]['f1']['f1']):.4f}\")\n",
    "    print(f\"AUC: {np.mean(all_seeds[seed]['f1']['auc']):.4f}\")\n",
    "\n",
    "print(\"\\n=== Final Cross-Seed Statistics ===\")\n",
    "print(f\"Accuracy: {compute_stats(final_metrics['acc'])}\")\n",
    "print(f\"Precision: {compute_stats(final_metrics['prec'])}\")\n",
    "print(f\"Recall: {compute_stats(final_metrics['rec'])}\")\n",
    "print(f\"F1 Score: {compute_stats(final_metrics['f1'])}\")\n",
    "print(f\"AUC: {compute_stats(final_metrics['auc'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Individual Seed Results ===\n",
      "\n",
      "Seed 0 - Best F1 Networks:\n",
      "Accuracy: 80.00% ± 0.30%\n",
      "Precision: 54.03% ± 0.48%\n",
      "Recall: 75.28% ± 1.61%\n",
      "F1: 62.90% ± 0.69%\n",
      "AUC: 86.68% ± 0.36%\n",
      "\n",
      "Seed 0 - Best Recall Networks:\n",
      "Accuracy: 66.39% ± 5.82%\n",
      "Precision: 39.87% ± 3.94%\n",
      "Recall: 90.32% ± 3.89%\n",
      "F1: 55.09% ± 3.14%\n",
      "AUC: 85.89% ± 0.52%\n",
      "\n",
      "Seed 1 - Best F1 Networks:\n",
      "Accuracy: 81.03% ± 1.74%\n",
      "Precision: 56.90% ± 4.51%\n",
      "Recall: 71.77% ± 6.65%\n",
      "F1: 63.01% ± 1.00%\n",
      "AUC: 86.58% ± 0.53%\n",
      "\n",
      "Seed 1 - Best Recall Networks:\n",
      "Accuracy: 68.48% ± 3.46%\n",
      "Precision: 41.18% ± 2.46%\n",
      "Recall: 90.17% ± 3.57%\n",
      "F1: 56.43% ± 1.76%\n",
      "AUC: 85.99% ± 1.05%\n",
      "\n",
      "=== Final Cross-Seed Statistics ===\n",
      "\n",
      "Best F1 Networks:\n",
      "Accuracy: 80.51% ± 0.52%\n",
      "Precision: 55.46% ± 1.44%\n",
      "Recall: 73.53% ± 1.76%\n",
      "F1 Score: 62.95% ± 0.06%\n",
      "AUC: 86.63% ± 0.05%\n",
      "\n",
      "Best Recall Networks:\n",
      "Accuracy: 67.43% ± 1.04%\n",
      "Precision: 40.53% ± 0.65%\n",
      "Recall: 90.24% ± 0.07%\n",
      "F1 Score: 55.76% ± 0.67%\n",
      "AUC: 85.94% ± 0.05%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "log_base_dir = r\"C:\\Users\\Admin\\Documents\\MasterThesis\\results\\Pneumonia\\ResNet50_Blur\\light_oversamp\"\n",
    "seeds = [0, 1]  # Two seeds to process\n",
    "num_folds = 5\n",
    "\n",
    "def process_seed(seed):\n",
    "    seed_metrics = {\n",
    "        'f1': {'acc': [], 'prec': [], 'rec': [], 'f1': [], 'auc': []},\n",
    "        'recall': {'acc': [], 'prec': [], 'rec': [], 'f1': [], 'auc': []}\n",
    "    }\n",
    "    \n",
    "    for fold in range(1, num_folds + 1):\n",
    "        log_dir = os.path.join(log_base_dir, f\"seed_{seed}\", f\"tensorboard_logs_fold_{fold}\")\n",
    "        if not os.path.exists(log_dir):\n",
    "            print(f\"Missing: {log_dir}\")\n",
    "            continue\n",
    "\n",
    "        event_acc = EventAccumulator(log_dir)\n",
    "        event_acc.Reload()\n",
    "        \n",
    "        # Extract metrics\n",
    "        metrics = {\n",
    "            'acc': [x.value * 100 for x in event_acc.Scalars(\"Accuracy/Validation\")],\n",
    "            'prec': [x.value * 100 for x in event_acc.Scalars(\"Metrics/Precision\")],\n",
    "            'rec': [x.value * 100 for x in event_acc.Scalars(\"Metrics/Recall\")],\n",
    "            'f1': [x.value * 100 for x in event_acc.Scalars(\"Metrics/F1\")],\n",
    "            'auc': [x.value * 100 for x in event_acc.Scalars(\"Metrics/AUC\")]\n",
    "        }\n",
    "\n",
    "        # Best F1 model\n",
    "        best_f1_idx = np.argmax(metrics['f1'])\n",
    "        seed_metrics['f1']['acc'].append(metrics['acc'][best_f1_idx])\n",
    "        seed_metrics['f1']['prec'].append(metrics['prec'][best_f1_idx])\n",
    "        seed_metrics['f1']['rec'].append(metrics['rec'][best_f1_idx])\n",
    "        seed_metrics['f1']['f1'].append(metrics['f1'][best_f1_idx])\n",
    "        seed_metrics['f1']['auc'].append(metrics['auc'][best_f1_idx])\n",
    "\n",
    "        # Best Recall model\n",
    "        best_rec_idx = np.argmax(metrics['rec'])\n",
    "        seed_metrics['recall']['acc'].append(metrics['acc'][best_rec_idx])\n",
    "        seed_metrics['recall']['prec'].append(metrics['prec'][best_rec_idx])\n",
    "        seed_metrics['recall']['rec'].append(metrics['rec'][best_rec_idx])\n",
    "        seed_metrics['recall']['f1'].append(metrics['f1'][best_rec_idx])\n",
    "        seed_metrics['recall']['auc'].append(metrics['auc'][best_rec_idx])\n",
    "    \n",
    "    return seed_metrics\n",
    "\n",
    "def compute_stats(data):\n",
    "    return f\"{np.mean(data):.2f}% ± {np.std(data):.2f}%\"\n",
    "\n",
    "# Process both seeds\n",
    "all_seeds = {seed: process_seed(seed) for seed in seeds}\n",
    "\n",
    "# Aggregate results across seeds for both F1 and Recall networks\n",
    "final_metrics = {\n",
    "    'f1': {\n",
    "        'acc': [],\n",
    "        'prec': [],\n",
    "        'rec': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    },\n",
    "    'recall': {\n",
    "        'acc': [],\n",
    "        'prec': [],\n",
    "        'rec': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    }\n",
    "}\n",
    "\n",
    "for seed in seeds:\n",
    "    # For F1 models\n",
    "    f1_data = all_seeds[seed]['f1']\n",
    "    final_metrics['f1']['acc'].append(np.mean(f1_data['acc']))\n",
    "    final_metrics['f1']['prec'].append(np.mean(f1_data['prec']))\n",
    "    final_metrics['f1']['rec'].append(np.mean(f1_data['rec']))\n",
    "    final_metrics['f1']['f1'].append(np.mean(f1_data['f1']))\n",
    "    final_metrics['f1']['auc'].append(np.mean(f1_data['auc']))\n",
    "    \n",
    "    # For Recall models\n",
    "    recall_data = all_seeds[seed]['recall']\n",
    "    final_metrics['recall']['acc'].append(np.mean(recall_data['acc']))\n",
    "    final_metrics['recall']['prec'].append(np.mean(recall_data['prec']))\n",
    "    final_metrics['recall']['rec'].append(np.mean(recall_data['rec']))\n",
    "    final_metrics['recall']['f1'].append(np.mean(recall_data['f1']))\n",
    "    final_metrics['recall']['auc'].append(np.mean(recall_data['auc']))\n",
    "\n",
    "# Print results\n",
    "print(\"=== Individual Seed Results ===\")\n",
    "for seed in seeds:\n",
    "    print(f\"\\nSeed {seed} - Best F1 Networks:\")\n",
    "    print(f\"Accuracy: {np.mean(all_seeds[seed]['f1']['acc']):.2f}% ± {np.std(all_seeds[seed]['f1']['acc']):.2f}%\")\n",
    "    print(f\"Precision: {np.mean(all_seeds[seed]['f1']['prec']):.2f}% ± {np.std(all_seeds[seed]['f1']['prec']):.2f}%\")\n",
    "    print(f\"Recall: {np.mean(all_seeds[seed]['f1']['rec']):.2f}% ± {np.std(all_seeds[seed]['f1']['rec']):.2f}%\") \n",
    "    print(f\"F1: {np.mean(all_seeds[seed]['f1']['f1']):.2f}% ± {np.std(all_seeds[seed]['f1']['f1']):.2f}%\")\n",
    "    print(f\"AUC: {np.mean(all_seeds[seed]['f1']['auc']):.2f}% ± {np.std(all_seeds[seed]['f1']['auc']):.2f}%\")\n",
    "    \n",
    "    print(f\"\\nSeed {seed} - Best Recall Networks:\")\n",
    "    print(f\"Accuracy: {np.mean(all_seeds[seed]['recall']['acc']):.2f}% ± {np.std(all_seeds[seed]['recall']['acc']):.2f}%\")\n",
    "    print(f\"Precision: {np.mean(all_seeds[seed]['recall']['prec']):.2f}% ± {np.std(all_seeds[seed]['recall']['prec']):.2f}%\")\n",
    "    print(f\"Recall: {np.mean(all_seeds[seed]['recall']['rec']):.2f}% ± {np.std(all_seeds[seed]['recall']['rec']):.2f}%\") \n",
    "    print(f\"F1: {np.mean(all_seeds[seed]['recall']['f1']):.2f}% ± {np.std(all_seeds[seed]['recall']['f1']):.2f}%\")\n",
    "    print(f\"AUC: {np.mean(all_seeds[seed]['recall']['auc']):.2f}% ± {np.std(all_seeds[seed]['recall']['auc']):.2f}%\")\n",
    "\n",
    "print(\"\\n=== Final Cross-Seed Statistics ===\")\n",
    "print(\"\\nBest F1 Networks:\")\n",
    "print(f\"Accuracy: {compute_stats(final_metrics['f1']['acc'])}\")\n",
    "print(f\"Precision: {compute_stats(final_metrics['f1']['prec'])}\")\n",
    "print(f\"Recall: {compute_stats(final_metrics['f1']['rec'])}\")\n",
    "print(f\"F1 Score: {compute_stats(final_metrics['f1']['f1'])}\")\n",
    "print(f\"AUC: {compute_stats(final_metrics['f1']['auc'])}\")\n",
    "\n",
    "print(\"\\nBest Recall Networks:\")\n",
    "print(f\"Accuracy: {compute_stats(final_metrics['recall']['acc'])}\")\n",
    "print(f\"Precision: {compute_stats(final_metrics['recall']['prec'])}\")\n",
    "print(f\"Recall: {compute_stats(final_metrics['recall']['rec'])}\")\n",
    "print(f\"F1 Score: {compute_stats(final_metrics['recall']['f1'])}\")\n",
    "print(f\"AUC: {compute_stats(final_metrics['recall']['auc'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
