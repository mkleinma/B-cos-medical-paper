{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8b625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Admin/.cache\\torch\\hub\\B-cos_B-cos-v2_main\n",
      "g:\\Meine Ablage\\Universität\\Master Thesis\\Multi-Classification\\evaluation\\libraries_multilabel\\MultiLabelExplanationWrapper.py:43: UserWarning: Input tensor did not require grad! Has been set automatically to True!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Energy-Based Pointing Game Results by Class:\n",
      "             Class  Avg Total  Avg Correct  Avg Incorrect  Correct Count  Incorrect Count  Total Samples\n",
      "Aortic enlargement     0.1880       0.1852         0.2004            497              114            611\n",
      "       Atelectasis     0.3591       0.3756         0.3494             14               24             38\n",
      "     Calcification     0.2033       0.2764         0.2024              1               90             91\n",
      "      Cardiomegaly     0.2371       0.2364         0.2389            329              131            460\n",
      "     Consolidation     0.3594       0.4531         0.3115             24               47             71\n",
      "               ILD     0.3996       0.4838         0.3856             11               66             77\n",
      "      Infiltration     0.3005       0.3574         0.2797             33               90            123\n",
      "      Lung Opacity     0.2616       0.3418         0.1911            124              141            265\n",
      "       Nodule/Mass     0.1664       0.1784         0.1645             23              142            165\n",
      "      Other lesion     0.2310       0.2870         0.2182             42              185            227\n",
      "  Pleural effusion     0.2900       0.3432         0.1881            136               71            207\n",
      "Pleural thickening     0.2026       0.2085         0.1961            209              188            397\n",
      "      Pneumothorax     0.4488       0.5211         0.4295              4               15             19\n",
      "Pulmonary fibrosis     0.2113       0.2342         0.1808            185              139            324\n"
     ]
    }
   ],
   "source": [
    "from libraries_multilabel.energyPointGame import energy_point_game_mask\n",
    "from libraries_multilabel.bcosconv2d import NormedConv2d\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#from dataset.augmentations import no_augmentations\n",
    "from libraries_multilabel.bcosconv2d import NormedConv2d\n",
    "#from blurpool.blur_bcosconv2d import ModifiedBcosConv2d\n",
    "#from pooling.flc_bcosconv2d import ModifiedFLCBcosConv2d\n",
    "from libraries_multilabel.bcoslinear import BcosLinear\n",
    "from libraries_multilabel.MultiLabelExplanationWrapper import MultiLabelModelWrapper\n",
    "from libraries_multilabel.MultiLabelDatasets import MultiLabelDatasetID\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "original_width, original_height = 1024, 1024\n",
    "explanation_width, explanation_height = 224, 224\n",
    "\n",
    "image_folder = r\"D:\\vinbigdata-chest-xray-abnormalities-detection\\train_png_224\"\n",
    "model_path = r\"C:\\Users\\Admin\\Documents\\MasterThesis\\results\\VinBigData\\ResNet_Bcos\\no_nosamp\\seed_0\\pneumonia_detection_model_resnet_bcos_bestf1_1.pth\"\n",
    "csv_path_boxes = r\"D:\\vinbigdata-chest-xray-abnormalities-detection\\train224.csv\"\n",
    "csv_path = r\"G:\\Meine Ablage\\Universität\\Master Thesis\\Multi-Classification\\training\\multilabel_dataset.csv\"\n",
    "splits_path = r\"G:\\Meine Ablage\\Universität\\Master Thesis\\Multi-Classification\\training\\vinbigdata_5fold_splits.pkl\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#model = torch.hub.load('B-cos/B-cos-v2', 'vitc_b_patch1_14', pretrained=True)\n",
    "#model[0].linear_head.linear = BcosLinear(in_features=768, out_features=2, bias=False, b=2)\n",
    "\n",
    "model = torch.hub.load('B-cos/B-cos-v2', 'resnet50', pretrained=True)\n",
    "model.fc.linear = NormedConv2d(2048, 14, kernel_size=(1, 1), stride=(1, 1), bias=False) # code from B-cos paper reused to adjust network\n",
    "\n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "data = pd.read_csv(csv_path)\n",
    "data_boxes = pd.read_csv(csv_path_boxes)\n",
    "\n",
    "with open(splits_path, 'rb') as f:\n",
    "    splits = pickle.load(f)\n",
    "\n",
    "# Loop over whole validation set of first fold \n",
    "first_split = splits[0] # fold selection\n",
    "val_idx = first_split[1]  # Only use the validation indices from the first fold\n",
    "val_data = data.iloc[val_idx]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "val_dataset = MultiLabelDatasetID(val_data, image_folder, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "scale_x = explanation_width / original_width\n",
    "scale_y = explanation_height / original_height\n",
    "\n",
    "\n",
    "class_names = [\n",
    "    \"Aortic enlargement\", \"Atelectasis\", \"Calcification\", \"Cardiomegaly\",\n",
    "    \"Consolidation\", \"ILD\", \"Infiltration\", \"Lung Opacity\",\n",
    "    \"Nodule/Mass\", \"Other lesion\", \"Pleural effusion\", \"Pleural thickening\",\n",
    "    \"Pneumothorax\", \"Pulmonary fibrosis\"]\n",
    "\n",
    "# Initialize results storage\n",
    "class_results = {name: {\n",
    "    'proportions': [],\n",
    "    'correct': [],\n",
    "    'incorrect': [],\n",
    "    'correct_count': 0,\n",
    "    'incorrect_count': 0\n",
    "} for name in class_names}\n",
    "\n",
    "proportions = []\n",
    "proportions_correct = []\n",
    "proportions_incorrect = []\n",
    "count_correct = 0\n",
    "count_incorrect = 0\n",
    "multiLabelWrapper = MultiLabelModelWrapper(model)\n",
    "model.eval()\n",
    "multiLabelWrapper.model.eval()\n",
    "\n",
    "with torch.enable_grad():\n",
    "    for images, labels, image_ids in val_loader:\n",
    "        labels = labels.to(device)\n",
    "        six_channel_images = []\n",
    "        for img_tensor in images:\n",
    "            numpy_image = (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "            pil_image = Image.fromarray(numpy_image)\n",
    "            transformed_image = model.transform(pil_image)\n",
    "            six_channel_images.append(transformed_image)\n",
    "            \n",
    "        six_channel_images = torch.stack(six_channel_images).to(device)\n",
    "        \n",
    "        mask = torch.zeros((224, 224), dtype=torch.int32)\n",
    "        for image, label, image_id in zip(six_channel_images, labels, image_ids):\n",
    "            image = image[None]\n",
    "            outputs = model(image)\n",
    "            prediction = torch.sigmoid(outputs)\n",
    "            expl = multiLabelWrapper.explain(image)\n",
    "            for class_idx, class_name in enumerate(class_names):\n",
    "                filtered_rows = data_boxes[(data_boxes['image_id'] == image_id)]\n",
    "                labels_row = data[data['image_id'] == image_id]\n",
    "            \n",
    "                if (not filtered_rows.empty) and (not labels_row.empty) and (labels_row[class_name].iloc[0] == 1):  \n",
    "                    prediction = expl[\"binary_predictions\"][0][class_idx]\n",
    "                    contribution_map = expl['contribution_maps'][class_idx]\n",
    "                    contribution_map[contribution_map<0] = 0  \n",
    "                    proportion = 0.0\n",
    "                    mask.zero_()\n",
    "                    for _, row in filtered_rows.iterrows():\n",
    "                        x_min = int(row[\"x_min\"])\n",
    "                        y_min = int(row[\"y_min\"])\n",
    "                        x_max = int(row[\"x_max\"])\n",
    "                        y_max = int(row[\"y_max\"])\n",
    "                        mask[y_min:y_max, x_min:x_max] = 1.0\n",
    "\n",
    "                    ebpg_result = energy_point_game_mask(mask.cpu(), contribution_map.cpu())\n",
    "                    class_results[class_name]['proportions'].append(ebpg_result)\n",
    "                        \n",
    "                    if prediction == 1:\n",
    "                        class_results[class_name]['correct'].append(ebpg_result)\n",
    "                        class_results[class_name]['correct_count'] += 1\n",
    "                    else:\n",
    "                        class_results[class_name]['incorrect'].append(ebpg_result)\n",
    "                        class_results[class_name]['incorrect_count'] += 1\n",
    "                \n",
    "\n",
    "results = []\n",
    "for class_name in class_names:\n",
    "    data = class_results[class_name]\n",
    "    if data['proportions']:\n",
    "        avg_total = sum(data['proportions']) / len(data['proportions'])\n",
    "        avg_correct = sum(data['correct']) / len(data['correct']) if data['correct'] else 0\n",
    "        avg_incorrect = sum(data['incorrect']) / len(data['incorrect']) if data['incorrect'] else 0\n",
    "    else:\n",
    "        avg_total = avg_correct = avg_incorrect = 0\n",
    "        \n",
    "    results.append({\n",
    "        'Class': class_name,\n",
    "        'Avg Total': round(avg_total, 4),\n",
    "        'Avg Correct': round(avg_correct, 4),\n",
    "        'Avg Incorrect': round(avg_incorrect, 4),\n",
    "        'Correct Count': data['correct_count'],\n",
    "        'Incorrect Count': data['incorrect_count'],\n",
    "        'Total Samples': len(data['proportions'])\n",
    "    })\n",
    "\n",
    "# Create and print dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nEnergy-Based Pointing Game Results by Class:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f17234",
   "metadata": {},
   "source": [
    "# Calculate over all five folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52bc460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries_multilabel.energyPointGame import energy_point_game_mask\n",
    "from libraries_multilabel.bcosconv2d import NormedConv2d\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from libraries_multilabel.bcoslinear import BcosLinear\n",
    "from libraries_multilabel.MultiLabelExplanationWrapper import MultiLabelModelWrapper\n",
    "from libraries_multilabel.MultiLabelDatasets import MultiLabelDatasetID\n",
    "\n",
    "# Configuration\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path configurations\n",
    "image_folder = r\"D:\\vinbigdata-chest-xray-abnormalities-detection\\train_png_224\"\n",
    "csv_path_boxes = r\"D:\\vinbigdata-chest-xray-abnormalities-detection\\train224.csv\"\n",
    "csv_path = r\"G:\\Meine Ablage\\Universität\\Master Thesis\\Multi-Classification\\training\\multilabel_dataset.csv\"\n",
    "splits_path = r\"G:\\Meine Ablage\\Universität\\Master Thesis\\Multi-Classification\\training\\vinbigdata_5fold_splits.pkl\"\n",
    "\n",
    "# Initialize datasets and transforms\n",
    "data = pd.read_csv(csv_path)\n",
    "data_boxes = pd.read_csv(csv_path_boxes)\n",
    "with open(splits_path, 'rb') as f:\n",
    "    splits = pickle.load(f)\n",
    "    \n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "class_names = [\"Aortic enlargement\", \"Atelectasis\", \"Calcification\", \"Cardiomegaly\",\n",
    "    \"Consolidation\", \"ILD\", \"Infiltration\", \"Lung Opacity\",\n",
    "    \"Nodule/Mass\", \"Other lesion\", \"Pleural effusion\", \"Pleural thickening\",\n",
    "    \"Pneumothorax\", \"Pulmonary fibrosis\"]\n",
    "\n",
    "# Initialize results storage\n",
    "class_results = {name: {\n",
    "    'proportions': [],\n",
    "    'correct': [],\n",
    "    'incorrect': [],\n",
    "    'correct_count': 0,\n",
    "    'incorrect_count': 0\n",
    "} for name in class_names}\n",
    "\n",
    "# Process all 5 folds\n",
    "for fold in range(5):\n",
    "    print(f\"Processing fold {fold+1} of 5\")\n",
    "    \n",
    "    # 1. Load model for current fold\n",
    "    model_path = fr\"C:\\Users\\Admin\\Documents\\MasterThesis\\results\\VinBigData\\ResNet_Bcos\\no_nosamp\\seed_0\\pneumonia_detection_model_resnet_bcos_bestf1_{fold+1}.pth\"\n",
    "    \n",
    "    model = torch.hub.load('B-cos/B-cos-v2', 'resnet50', pretrained=True)\n",
    "    model.fc.linear = NormedConv2d(2048, 14, kernel_size=(1, 1), bias=False)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    \n",
    "    # 2. Setup validation data for current fold\n",
    "    val_idx = splits[fold][1]\n",
    "    val_data = data.iloc[val_idx]\n",
    "    val_dataset = MultiLabelDatasetID(val_data, image_folder, transform=transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    # 3. Process validation set\n",
    "    multiLabelWrapper = MultiLabelModelWrapper(model)\n",
    "    model.eval()\n",
    "    multiLabelWrapper.model.eval()\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        for images, labels, image_ids in val_loader:\n",
    "            labels = labels.to(device)\n",
    "            six_channel_images = []\n",
    "            \n",
    "            # Convert images to 6-channel format\n",
    "            for img_tensor in images:\n",
    "                numpy_image = (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "                pil_image = Image.fromarray(numpy_image)\n",
    "                transformed_image = model.transform(pil_image)\n",
    "                six_channel_images.append(transformed_image)\n",
    "            \n",
    "            six_channel_images = torch.stack(six_channel_images).to(device)\n",
    "            \n",
    "            # Generate explanations\n",
    "            mask = torch.zeros((224, 224), dtype=torch.int32)\n",
    "            for image, label, image_id in zip(six_channel_images, labels, image_ids):\n",
    "                image = image[None]  # Add batch dimension\n",
    "                expl = multiLabelWrapper.explain(image)\n",
    "                \n",
    "                # Process each class\n",
    "                for class_idx, class_name in enumerate(class_names):\n",
    "                    filtered_rows = data_boxes[(data_boxes['image_id'] == image_id)]\n",
    "                    labels_row = data[data['image_id'] == image_id]\n",
    "                    \n",
    "                    if not filtered_rows.empty and not labels_row.empty and labels_row[class_name].iloc[0] == 1:\n",
    "                        prediction = expl[\"binary_predictions\"][0][class_idx]\n",
    "                        contribution_map = expl['contribution_maps'][class_idx]\n",
    "                        contribution_map[contribution_map < 0] = 0\n",
    "                        \n",
    "                        # Create mask from bounding boxes\n",
    "                        mask.zero_()\n",
    "                        for _, row in filtered_rows.iterrows():\n",
    "                            x_min = int(row[\"x_min\"] * scale_x)\n",
    "                            y_min = int(row[\"y_min\"] * scale_y)\n",
    "                            x_max = int(row[\"x_max\"] * scale_x)\n",
    "                            y_max = int(row[\"y_max\"] * scale_y)\n",
    "                            mask[y_min:y_max, x_min:x_max] = 1.0\n",
    "                        \n",
    "                        # Calculate energy point game metric\n",
    "                        ebpg_result = energy_point_game_mask(mask.cpu(), contribution_map.cpu())\n",
    "                        \n",
    "                        # Update results\n",
    "                        class_results[class_name]['proportions'].append(ebpg_result)\n",
    "                        if prediction == 1:\n",
    "                            class_results[class_name]['correct'].append(ebpg_result)\n",
    "                            class_results[class_name]['correct_count'] += 1\n",
    "                        else:\n",
    "                            class_results[class_name]['incorrect'].append(ebpg_result)\n",
    "                            class_results[class_name]['incorrect_count'] += 1\n",
    "\n",
    "# Calculate final averaged results\n",
    "results = []\n",
    "for class_name in class_names:\n",
    "    data = class_results[class_name]\n",
    "    \n",
    "    avg_total = np.mean(data['proportions']) if data['proportions'] else 0\n",
    "    avg_correct = np.mean(data['correct']) if data['correct'] else 0\n",
    "    avg_incorrect = np.mean(data['incorrect']) if data['incorrect'] else 0\n",
    "    \n",
    "    results.append({\n",
    "        'Class': class_name,\n",
    "        'Avg Total': round(avg_total, 4),\n",
    "        'Avg Correct': round(avg_correct, 4),\n",
    "        'Avg Incorrect': round(avg_incorrect, 4),\n",
    "        'Correct Count': data['correct_count'],\n",
    "        'Incorrect Count': data['incorrect_count'],\n",
    "        'Total Samples': len(data['proportions'])\n",
    "    })\n",
    "\n",
    "# Display final results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nAverage Energy-Based Pointing Game Results Across All Folds:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b2725",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
